# coding=utf-8
# *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import warnings
import pulumi
import pulumi.runtime
from typing import Any, Dict, List, Mapping, Optional, Tuple, Union
from .. import _utilities, _tables
from . import outputs
from ._inputs import *

__all__ = ['Crawler']


class Crawler(pulumi.CustomResource):
    arn: pulumi.Output[str] = pulumi.property("arn")
    """
    The ARN of the crawler
    """

    catalog_targets: pulumi.Output[Optional[List['outputs.CrawlerCatalogTarget']]] = pulumi.property("catalogTargets")

    classifiers: pulumi.Output[Optional[List[str]]] = pulumi.property("classifiers")
    """
    List of custom classifiers. By default, all AWS classifiers are included in a crawl, but these custom classifiers always override the default classifiers for a given classification.
    """

    configuration: pulumi.Output[Optional[str]] = pulumi.property("configuration")
    """
    JSON string of configuration information.
    """

    database_name: pulumi.Output[str] = pulumi.property("databaseName")
    """
    Glue database where results are written.
    """

    description: pulumi.Output[Optional[str]] = pulumi.property("description")
    """
    Description of the crawler.
    """

    dynamodb_targets: pulumi.Output[Optional[List['outputs.CrawlerDynamodbTarget']]] = pulumi.property("dynamodbTargets")
    """
    List of nested DynamoDB target arguments. See below.
    """

    jdbc_targets: pulumi.Output[Optional[List['outputs.CrawlerJdbcTarget']]] = pulumi.property("jdbcTargets")
    """
    List of nested JBDC target arguments. See below.
    """

    name: pulumi.Output[str] = pulumi.property("name")
    """
    Name of the crawler.
    """

    role: pulumi.Output[str] = pulumi.property("role")
    """
    The IAM role friendly name (including path without leading slash), or ARN of an IAM role, used by the crawler to access other resources.
    """

    s3_targets: pulumi.Output[Optional[List['outputs.CrawlerS3Target']]] = pulumi.property("s3Targets")
    """
    List nested Amazon S3 target arguments. See below.
    """

    schedule: pulumi.Output[Optional[str]] = pulumi.property("schedule")
    """
    A cron expression used to specify the schedule. For more information, see [Time-Based Schedules for Jobs and Crawlers](https://docs.aws.amazon.com/glue/latest/dg/monitor-data-warehouse-schedule.html). For example, to run something every day at 12:15 UTC, you would specify: `cron(15 12 * * ? *)`.
    """

    schema_change_policy: pulumi.Output[Optional['outputs.CrawlerSchemaChangePolicy']] = pulumi.property("schemaChangePolicy")
    """
    Policy for the crawler's update and deletion behavior.
    """

    security_configuration: pulumi.Output[Optional[str]] = pulumi.property("securityConfiguration")
    """
    The name of Security Configuration to be used by the crawler
    """

    table_prefix: pulumi.Output[Optional[str]] = pulumi.property("tablePrefix")
    """
    The table prefix used for catalog tables that are created.
    """

    tags: pulumi.Output[Optional[Mapping[str, str]]] = pulumi.property("tags")
    """
    Key-value map of resource tags
    """

    def __init__(__self__,
                 resource_name,
                 opts: Optional[pulumi.ResourceOptions] = None,
                 catalog_targets: Optional[pulumi.Input[List[pulumi.Input[pulumi.InputType['CrawlerCatalogTargetArgs']]]]] = None,
                 classifiers: Optional[pulumi.Input[List[pulumi.Input[str]]]] = None,
                 configuration: Optional[pulumi.Input[str]] = None,
                 database_name: Optional[pulumi.Input[str]] = None,
                 description: Optional[pulumi.Input[str]] = None,
                 dynamodb_targets: Optional[pulumi.Input[List[pulumi.Input[pulumi.InputType['CrawlerDynamodbTargetArgs']]]]] = None,
                 jdbc_targets: Optional[pulumi.Input[List[pulumi.Input[pulumi.InputType['CrawlerJdbcTargetArgs']]]]] = None,
                 name: Optional[pulumi.Input[str]] = None,
                 role: Optional[pulumi.Input[str]] = None,
                 s3_targets: Optional[pulumi.Input[List[pulumi.Input[pulumi.InputType['CrawlerS3TargetArgs']]]]] = None,
                 schedule: Optional[pulumi.Input[str]] = None,
                 schema_change_policy: Optional[pulumi.Input[pulumi.InputType['CrawlerSchemaChangePolicyArgs']]] = None,
                 security_configuration: Optional[pulumi.Input[str]] = None,
                 table_prefix: Optional[pulumi.Input[str]] = None,
                 tags: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]] = None,
                 __props__=None,
                 __name__=None,
                 __opts__=None):
        """
        Manages a Glue Crawler. More information can be found in the [AWS Glue Developer Guide](https://docs.aws.amazon.com/glue/latest/dg/add-crawler.html)

        ## Example Usage
        ### DynamoDB Target

        ```python
        import pulumi
        import pulumi_aws as aws

        example = aws.glue.Crawler("example",
            database_name=aws_glue_catalog_database["example"]["name"],
            dynamodb_targets=[{
                "path": "table-name",
            }],
            role=aws_iam_role["example"]["arn"])
        ```
        ### JDBC Target

        ```python
        import pulumi
        import pulumi_aws as aws

        example = aws.glue.Crawler("example",
            database_name=aws_glue_catalog_database["example"]["name"],
            jdbc_targets=[{
                "connectionName": aws_glue_connection["example"]["name"],
                "path": "database-name/%",
            }],
            role=aws_iam_role["example"]["arn"])
        ```
        ### S3 Target

        ```python
        import pulumi
        import pulumi_aws as aws

        example = aws.glue.Crawler("example",
            database_name=aws_glue_catalog_database["example"]["name"],
            role=aws_iam_role["example"]["arn"],
            s3_targets=[{
                "path": f"s3://{aws_s3_bucket['example']['bucket']}",
            }])
        ```
        ### Catalog Target

        ```python
        import pulumi
        import pulumi_aws as aws

        example = aws.glue.Crawler("example",
            catalog_targets=[{
                "database_name": aws_glue_catalog_database["example"]["name"],
                "tables": [aws_glue_catalog_table["example"]["name"]],
            }],
            configuration=\"\"\"{
          "Version":1.0,
          "Grouping": {
            "TableGroupingPolicy": "CombineCompatibleSchemas"
          }
        }

        \"\"\",
            database_name=aws_glue_catalog_database["example"]["name"],
            role=aws_iam_role["example"]["arn"],
            schema_change_policy={
                "deleteBehavior": "LOG",
            })
        ```

        :param str resource_name: The name of the resource.
        :param pulumi.ResourceOptions opts: Options for the resource.
        :param pulumi.Input[List[pulumi.Input[str]]] classifiers: List of custom classifiers. By default, all AWS classifiers are included in a crawl, but these custom classifiers always override the default classifiers for a given classification.
        :param pulumi.Input[str] configuration: JSON string of configuration information.
        :param pulumi.Input[str] database_name: Glue database where results are written.
        :param pulumi.Input[str] description: Description of the crawler.
        :param pulumi.Input[List[pulumi.Input[pulumi.InputType['CrawlerDynamodbTargetArgs']]]] dynamodb_targets: List of nested DynamoDB target arguments. See below.
        :param pulumi.Input[List[pulumi.Input[pulumi.InputType['CrawlerJdbcTargetArgs']]]] jdbc_targets: List of nested JBDC target arguments. See below.
        :param pulumi.Input[str] name: Name of the crawler.
        :param pulumi.Input[str] role: The IAM role friendly name (including path without leading slash), or ARN of an IAM role, used by the crawler to access other resources.
        :param pulumi.Input[List[pulumi.Input[pulumi.InputType['CrawlerS3TargetArgs']]]] s3_targets: List nested Amazon S3 target arguments. See below.
        :param pulumi.Input[str] schedule: A cron expression used to specify the schedule. For more information, see [Time-Based Schedules for Jobs and Crawlers](https://docs.aws.amazon.com/glue/latest/dg/monitor-data-warehouse-schedule.html). For example, to run something every day at 12:15 UTC, you would specify: `cron(15 12 * * ? *)`.
        :param pulumi.Input[pulumi.InputType['CrawlerSchemaChangePolicyArgs']] schema_change_policy: Policy for the crawler's update and deletion behavior.
        :param pulumi.Input[str] security_configuration: The name of Security Configuration to be used by the crawler
        :param pulumi.Input[str] table_prefix: The table prefix used for catalog tables that are created.
        :param pulumi.Input[Mapping[str, pulumi.Input[str]]] tags: Key-value map of resource tags
        """
        if __name__ is not None:
            warnings.warn("explicit use of __name__ is deprecated", DeprecationWarning)
            resource_name = __name__
        if __opts__ is not None:
            warnings.warn("explicit use of __opts__ is deprecated, use 'opts' instead", DeprecationWarning)
            opts = __opts__
        if opts is None:
            opts = pulumi.ResourceOptions()
        if not isinstance(opts, pulumi.ResourceOptions):
            raise TypeError('Expected resource options to be a ResourceOptions instance')
        if opts.version is None:
            opts.version = _utilities.get_version()
        if opts.id is None:
            if __props__ is not None:
                raise TypeError('__props__ is only valid when passed in combination with a valid opts.id to get an existing resource')
            __props__ = dict()

            __props__['catalog_targets'] = catalog_targets
            __props__['classifiers'] = classifiers
            __props__['configuration'] = configuration
            if database_name is None:
                raise TypeError("Missing required property 'database_name'")
            __props__['database_name'] = database_name
            __props__['description'] = description
            __props__['dynamodb_targets'] = dynamodb_targets
            __props__['jdbc_targets'] = jdbc_targets
            __props__['name'] = name
            if role is None:
                raise TypeError("Missing required property 'role'")
            __props__['role'] = role
            __props__['s3_targets'] = s3_targets
            __props__['schedule'] = schedule
            __props__['schema_change_policy'] = schema_change_policy
            __props__['security_configuration'] = security_configuration
            __props__['table_prefix'] = table_prefix
            __props__['tags'] = tags
            __props__['arn'] = None
        super(Crawler, __self__).__init__(
            'aws:glue/crawler:Crawler',
            resource_name,
            __props__,
            opts)

    @staticmethod
    def get(resource_name: str,
            id: str,
            opts: Optional[pulumi.ResourceOptions] = None,
            arn: Optional[pulumi.Input[str]] = None,
            catalog_targets: Optional[pulumi.Input[List[pulumi.Input[pulumi.InputType['CrawlerCatalogTargetArgs']]]]] = None,
            classifiers: Optional[pulumi.Input[List[pulumi.Input[str]]]] = None,
            configuration: Optional[pulumi.Input[str]] = None,
            database_name: Optional[pulumi.Input[str]] = None,
            description: Optional[pulumi.Input[str]] = None,
            dynamodb_targets: Optional[pulumi.Input[List[pulumi.Input[pulumi.InputType['CrawlerDynamodbTargetArgs']]]]] = None,
            jdbc_targets: Optional[pulumi.Input[List[pulumi.Input[pulumi.InputType['CrawlerJdbcTargetArgs']]]]] = None,
            name: Optional[pulumi.Input[str]] = None,
            role: Optional[pulumi.Input[str]] = None,
            s3_targets: Optional[pulumi.Input[List[pulumi.Input[pulumi.InputType['CrawlerS3TargetArgs']]]]] = None,
            schedule: Optional[pulumi.Input[str]] = None,
            schema_change_policy: Optional[pulumi.Input[pulumi.InputType['CrawlerSchemaChangePolicyArgs']]] = None,
            security_configuration: Optional[pulumi.Input[str]] = None,
            table_prefix: Optional[pulumi.Input[str]] = None,
            tags: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]] = None) -> 'Crawler':
        """
        Get an existing Crawler resource's state with the given name, id, and optional extra
        properties used to qualify the lookup.

        :param str resource_name: The unique name of the resulting resource.
        :param str id: The unique provider ID of the resource to lookup.
        :param pulumi.ResourceOptions opts: Options for the resource.
        :param pulumi.Input[str] arn: The ARN of the crawler
        :param pulumi.Input[List[pulumi.Input[str]]] classifiers: List of custom classifiers. By default, all AWS classifiers are included in a crawl, but these custom classifiers always override the default classifiers for a given classification.
        :param pulumi.Input[str] configuration: JSON string of configuration information.
        :param pulumi.Input[str] database_name: Glue database where results are written.
        :param pulumi.Input[str] description: Description of the crawler.
        :param pulumi.Input[List[pulumi.Input[pulumi.InputType['CrawlerDynamodbTargetArgs']]]] dynamodb_targets: List of nested DynamoDB target arguments. See below.
        :param pulumi.Input[List[pulumi.Input[pulumi.InputType['CrawlerJdbcTargetArgs']]]] jdbc_targets: List of nested JBDC target arguments. See below.
        :param pulumi.Input[str] name: Name of the crawler.
        :param pulumi.Input[str] role: The IAM role friendly name (including path without leading slash), or ARN of an IAM role, used by the crawler to access other resources.
        :param pulumi.Input[List[pulumi.Input[pulumi.InputType['CrawlerS3TargetArgs']]]] s3_targets: List nested Amazon S3 target arguments. See below.
        :param pulumi.Input[str] schedule: A cron expression used to specify the schedule. For more information, see [Time-Based Schedules for Jobs and Crawlers](https://docs.aws.amazon.com/glue/latest/dg/monitor-data-warehouse-schedule.html). For example, to run something every day at 12:15 UTC, you would specify: `cron(15 12 * * ? *)`.
        :param pulumi.Input[pulumi.InputType['CrawlerSchemaChangePolicyArgs']] schema_change_policy: Policy for the crawler's update and deletion behavior.
        :param pulumi.Input[str] security_configuration: The name of Security Configuration to be used by the crawler
        :param pulumi.Input[str] table_prefix: The table prefix used for catalog tables that are created.
        :param pulumi.Input[Mapping[str, pulumi.Input[str]]] tags: Key-value map of resource tags
        """
        opts = pulumi.ResourceOptions.merge(opts, pulumi.ResourceOptions(id=id))

        __props__ = dict()

        __props__["arn"] = arn
        __props__["catalog_targets"] = catalog_targets
        __props__["classifiers"] = classifiers
        __props__["configuration"] = configuration
        __props__["database_name"] = database_name
        __props__["description"] = description
        __props__["dynamodb_targets"] = dynamodb_targets
        __props__["jdbc_targets"] = jdbc_targets
        __props__["name"] = name
        __props__["role"] = role
        __props__["s3_targets"] = s3_targets
        __props__["schedule"] = schedule
        __props__["schema_change_policy"] = schema_change_policy
        __props__["security_configuration"] = security_configuration
        __props__["table_prefix"] = table_prefix
        __props__["tags"] = tags
        return Crawler(resource_name, opts=opts, __props__=__props__)

    def translate_output_property(self, prop):
        return _tables.CAMEL_TO_SNAKE_CASE_TABLE.get(prop) or prop

    def translate_input_property(self, prop):
        return _tables.SNAKE_TO_CAMEL_CASE_TABLE.get(prop) or prop

